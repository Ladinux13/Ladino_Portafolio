{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50b6b0-e941-416e-9ea4-4fe3dec2db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### #### #### #### \n",
    "# #### #### #### #### \n",
    "# #### #### #### #### \n",
    "# #### #### #### #### Código de clasificacion SIPRE (QUEJAS-DENUNICAS-UNIDAD)\n",
    "\n",
    "### Ladino Álvarez Ricardo Arturo\n",
    "\n",
    "# #### #### #### #### Librerias # #### #### #### #### \n",
    "# #### #### #### ####  Base\n",
    "\n",
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from io import StringIO\n",
    "\n",
    "## #### > NLP\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "stopword = set(stopwords.words('spanish'))\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "spanish_stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "## #### > NLP\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,mean_squared_error\n",
    "\n",
    "## #### > Desbalance de clase\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "\n",
    "\n",
    "## #### > Errores\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46b8c3-366c-4290-a005-f3bfa09127fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## #### > Validación donde ambas bases tienen las mismas columnas\n",
    "if list(Quejas.columns) == list(Denucias.columns):\n",
    "    print(\"Ambas bases tienen los mismos nombres de columnas. Puedes concatenarlas.\")\n",
    "    # Concatenar si la validación es exitosa\n",
    "    datos_concatenados = pd.concat([Quejas, Denucias], ignore_index=True)\n",
    "    print(\"Concatenación exitosa.\")\n",
    "else:\n",
    "    print(\"Las columnas no coinciden entre las bases. Revisa los nombres de las columnas.\")\n",
    "    print(\"Columnas en Quejas:\", Quejas.columns.tolist())\n",
    "    print(\"Columnas en Denuncias:\", Denucias.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edd7a4-9b21-4ded-a881-50a883bb920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73161, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tipo asunto\n",
       "Denuncia    53102\n",
       "Queja       20059\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## #### > Función de representatividad\n",
    "\n",
    "def Repre_clase(Clase_Size):\n",
    "    if Clase_Size < 500:\n",
    "        return 1.0  # 100%\n",
    "    elif 500 <= Clase_Size <= 5000:\n",
    "        return 0.8  # 80%\n",
    "    else:\n",
    "        return 0.5  # 50%\n",
    "        \n",
    "Muestras = Remuestreo['Tipo asunto'].value_counts().apply(Repre_clase)\n",
    "\n",
    "## #### > Aplicar el muestreo por clase\n",
    "Datos_Muestra = Remuestreo.groupby('Tipo asunto').apply(lambda x: x.sample(frac = Muestras[x.name],\n",
    "                                                                            random_state = 42)).reset_index(drop = True)\n",
    "\n",
    "print(Datos_Muestra.shape)\n",
    "Datos_Muestra['Tipo asunto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4817c89b-680d-4634-8505-d885c8370901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tipo_asunto = pd.DataFrame(set(zip(Datos_Muestra['Tipo asunto'],\n",
    "                                      Datos_Muestra['Tipo_asunto'])),\n",
    "                              columns =['Queja_Denuncia', 'Code']).sort_values(by='Code', ascending = True)\n",
    "\n",
    "UA_Asignada = pd.DataFrame(set(zip(Datos_Muestra['UA Asignada'],\n",
    "                                      Datos_Muestra['UA_Asignada'])),\n",
    "                              columns =['UA_Asignada', 'Code']).sort_values(by='Code', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0016546a-e690-4912-b398-6eba6b4c3223",
   "metadata": {},
   "source": [
    "### Limpieza de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def3303b-ff11-4641-a80e-abaa04126210",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Función de Normalización del texto\n",
    "\n",
    "### Limpieza de texto\n",
    "def limpiar_texto(texto):\n",
    "    # > 00 - StopWords\n",
    "    # > 01 - Convertir a minúsculas\n",
    "    # > 02 - Eliminar signos de puntuación y números\n",
    "    # > 03 - Eliminar acentos y caracteres especiales\n",
    "    # > 04 Eliminar stopwords\n",
    "    # > 05 Eliminar palabras cortas\n",
    "    # > 06 Corrección ortográfica\n",
    "    # > 07 Lematización\n",
    "    return (texto)\n",
    "\n",
    "### Limpieza de múltiples columnas\n",
    "def limpiar_columnas(df, columnas):\n",
    "    for columna in columnas:\n",
    "        df[columna] = df[columna].astype(str).fillna('')  # Convertir a string y manejar NaNs\n",
    "        df[columna] = df[columna].apply(limpiar_texto)    # Aplicar la función de limpieza completa\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a64c07d0-8d28-4ff0-aa32-91cfaf7954ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Datos_Muestra_N = Datos_Muestra.copy()\n",
    "Columnas_Limpia = ['Descripción de los Hechos'] \n",
    "Datos_Muestra_N = limpiar_columnas(Datos_Muestra_N, Columnas_Limpia)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75933ed3-759d-4735-8919-649e4414177b",
   "metadata": {},
   "source": [
    "### Prueba y entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0b714e7-e303-4493-9096-4d0132f1c149",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Datos_Muestra_N['Descripción de los Hechos'],\n",
    "                                                    Datos_Muestra_N['Tipo_asunto'],\n",
    "                                                    stratify = Datos_Muestra_N['Tipo_asunto'],\n",
    "                                                    test_size = 0.60,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a283544-ed29-4a52-874f-c887a5ed90cf",
   "metadata": {},
   "source": [
    "### Vector de aprendizaje + Bolsa de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fef59f84-188f-45e5-853d-06de81935c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = TfidfVectorizer(strip_accents = 'unicode', \n",
    "                        analyzer = 'word',\n",
    "                        max_features = 10000,\n",
    "                        norm='l2',\n",
    "                        encoding = 'latin-1',\n",
    "                        token_pattern = r'\\w{1,}',\n",
    "                        ngram_range = (1, 2), \n",
    "                        use_idf = True,\n",
    "                        smooth_idf = True, \n",
    "                        sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "673bf6eb-fa18-495e-bb93-f8b614a4cb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "TDFT = TFIDF.fit(list(X_train) + list(X_test))\n",
    "X_train_N =  TDFT.transform(X_train) \n",
    "X_test_N = TFIDF.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60fc144b-c70b-4612-b100-4ded66ceb745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(TDFT, open(\"Palabras_Tipo_Asunto.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2ba5ef86-163b-47c3-b4ef-10fc891602e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([21241,  8023]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db91cb77-372a-4337-aecd-e530d860d3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ================================= ================================= =============================== ###\n",
    "### ========================================= QUEJAS & DENUNCIAS ====================================== ###\n",
    "### ============================== FUNCIÓN DE APRENDIZAJE MAQUINA ===================================== ###\n",
    "\n",
    "def Aprendizaje_Queja_Denuncia(X_train, X_test, y_train, y_test, Model):\n",
    "    ''' Función de modelo de aprendizaje, que ejecuta lo siguiente:\n",
    "        A) Se evaluan diferentes modelos : Random Forest, Naibe Bayes y XGBoost '''\n",
    "    \n",
    "    if Model == \"Random_Forest\":\n",
    "        \n",
    "        Ranf_clf = {'n_estimators': [64, 128, 256, 512, 1024],\n",
    "                    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                    'max_depth': [2, 4, 8, 16, 32, 64, 128],\n",
    "                    'criterion': ['gini', 'entropy']\n",
    "                   }\n",
    "        \n",
    "        estimador_RF = RandomForestClassifier(random_state = 42,\n",
    "                                              n_jobs = multiprocessing.cpu_count()-1)\n",
    "        \n",
    "        RF_CECTI = GridSearchCV(estimator = estimador_RF,\n",
    "                                param_grid = Ranf_clf,\n",
    "                                cv = RepeatedKFold(n_splits = 3, \n",
    "                                                   n_repeats = 1, \n",
    "                                                   random_state = 42),\n",
    "                                scoring = 'accuracy',\n",
    "                                refit = True,\n",
    "                                verbose = 0,\n",
    "                                return_train_score = True)\n",
    "        \n",
    "        CECTI_RF = RF_CECTI.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_RF.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_RF_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        RF_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"Random Forest > Accuracy: \", np.round((RF_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "        \n",
    "    elif Model == \"Naibe_Bayes\":\n",
    "        \n",
    "        n_classes = np.unique(y_train)\n",
    "        \n",
    "        params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                  'fit_prior': [True, False],\n",
    "                  'class_prior': [None, [0.1,]* len(n_classes)]\n",
    "                 }\n",
    "        \n",
    "        Esti_MNB = MultinomialNB()\n",
    "        \n",
    "        MNB_grid = GridSearchCV(Esti_MNB,\n",
    "                                param_grid = params, \n",
    "                                n_jobs = multiprocessing.cpu_count()-1,\n",
    "                                cv = RepeatedKFold(n_splits = 3, n_repeats = 1,\n",
    "                                                   random_state = 42),\n",
    "                                verbose =0 )\n",
    "        \n",
    "        CECTI_MNB = MNB_grid.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_MNB.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_NB_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        NB_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"Naibe Bayes > Accuracy: \", np.round((NB_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "    \n",
    "    elif Model == \"XGBoost\":\n",
    "        \n",
    "        xgb_params = {'max_depth':[None, 1, 3, 5, 10, 20, 30],\n",
    "                      'learning_rate':[0.001, 0.01, 0.1],\n",
    "                      'n_estimators': [50, 100, 200]\n",
    "                     }\n",
    "        \n",
    "        Esti_XGB = xgb.XGBClassifier(objective = 'multi:softprob')\n",
    "        \n",
    "        XGB_grid = GridSearchCV(estimator = Esti_XGB,\n",
    "                                param_grid = xgb_params,\n",
    "                                n_jobs = multiprocessing.cpu_count()-1,\n",
    "                                cv = RepeatedKFold(n_splits = 5, \n",
    "                                                   n_repeats = 3, \n",
    "                                                   random_state = 42),\n",
    "                                scoring='accuracy',\n",
    "                                verbose = 0)\n",
    "        \n",
    "        CECTI_XGB = XGB_grid.fit(X_train,y_train)\n",
    "        \n",
    "        Best_estimador = CECTI_XGB.best_estimator_\n",
    "        \n",
    "        pickle.dump(Best_estimador, open(\"Estimador_XGB_QD.pkl\", \"wb\"))\n",
    "        \n",
    "        y_hat = Best_estimador.predict(X = X_test)\n",
    "        \n",
    "        XG_accuracy = metrics.accuracy_score(y_hat, y_test)\n",
    "        \n",
    "        print(\"----------------------------\")\n",
    "        print(\"----------------------------\")\n",
    "        print (\"XGBoost > Accuracy: \", np.round((XG_accuracy*100), 3), '%')\n",
    "        print(\"----------------------------\")\n",
    "        print('Reporte de clasificación: \\n', classification_report(y_test, y_hat))\n",
    "    \n",
    "    return(Best_estimador)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c58be6fd-aaf5-4a36-9044-34ffc05cd718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "----------------------------\n",
      "Random Forest > Accuracy:  97.638 %\n",
      "----------------------------\n",
      "Reporte de clasificación: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     31861\n",
      "           1       0.93      0.99      0.96     12036\n",
      "\n",
      "    accuracy                           0.98     43897\n",
      "   macro avg       0.96      0.98      0.97     43897\n",
      "weighted avg       0.98      0.98      0.98     43897\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=128, max_features=&#x27;auto&#x27;, n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=128, max_features=&#x27;auto&#x27;, n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=128, max_features='auto', n_estimators=64,\n",
       "                       n_jobs=7, random_state=42)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Aprendizaje_Queja_Denuncia(X_train_N, X_test_N, y_train, y_test, \"Random_Forest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
