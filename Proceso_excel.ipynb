{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3cb47-91db-4095-9924-10f72b8c3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Optimización de procesos de excel a python - Cuentas\n",
    "### Ladino Álvarez Ricardo Arturo\n",
    "\n",
    "\n",
    "### Librerias\n",
    "\n",
    "import os\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e436d70d-826d-4e40-836f-a6ca81a7bd65",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Función : Identificacion automáticamente de fila y columna donde comienza la tabla en la hoja (con imagen, texto aleatorio, etc)\n",
    "##\n",
    "#\n",
    "def Tabla_Excel(ruta_archivo, hoja=0):\n",
    "    \"\"\"\n",
    "    Carga una tabla desde un archivo de Excel y devuelve un DataFrame de Pandas.\n",
    "\n",
    "    La función identifica automáticamente la fila y columna donde comienza la tabla en la hoja\n",
    "    de Excel especificada y ajusta la lectura del archivo para capturar únicamente los datos relevantes.\n",
    "\n",
    "    Argumentos:\n",
    "    ruta_archivo : str\n",
    "        Ruta del archivo de Excel.\n",
    "    hoja : int o str, opcional\n",
    "        Número de la hoja (por defecto es 0, la primera hoja) o nombre de la hoja a leer.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame\n",
    "        Un DataFrame que contiene la tabla encontrada en el archivo de Excel.\n",
    "\n",
    "    Excepciones:\n",
    "    ValueError\n",
    "        Si no se encuentra ninguna tabla con al menos dos valores en una fila.\n",
    "    \"\"\"\n",
    "    # Carga el archivo de Excel usando openpyxl\n",
    "    wb = load_workbook(ruta_archivo, data_only=True)\n",
    "\n",
    "    # Selecciona la hoja a procesar\n",
    "    ws = wb[wb.sheetnames[hoja]] if isinstance(hoja, int) else wb[hoja]\n",
    "\n",
    "    # Inicializa las variables para la fila y columna donde comienza la tabla\n",
    "    inicio_fila = None\n",
    "    inicio_columna = None\n",
    "\n",
    "    # Itera sobre las filas y columnas para detectar la primera fila con datos relevantes\n",
    "    for i, row in enumerate(ws.iter_rows(min_row=1, max_row=ws.max_row, min_col=1, max_col=ws.max_column), start=1):\n",
    "        # Obtiene los valores no nulos en la fila\n",
    "        valores_fila = [cell.value for cell in row if cell.value is not None]\n",
    "        \n",
    "        # Si hay más de un valor en la fila, asume que es el inicio de la tabla\n",
    "        if len(valores_fila) > 1: \n",
    "            inicio_fila = i  # Guarda el número de fila donde comienza la tabla\n",
    "            # Detecta la primera columna con un valor no nulo en la fila\n",
    "            inicio_columna = next((j for j, cell in enumerate(row, start=1) if cell.value is not None), 1)\n",
    "            break\n",
    "    \n",
    "    # Si no se encuentra ninguna tabla, lanza una excepción\n",
    "    if inicio_fila is None:\n",
    "        raise ValueError(f\"No se encontró ninguna tabla en el archivo {ruta_archivo}.\")\n",
    "\n",
    "    # Lee la tabla desde la hoja de Excel usando Pandas, saltando las filas iniciales vacías\n",
    "    df = pd.read_excel(ruta_archivo,\n",
    "                       sheet_name=hoja,\n",
    "                       skiprows=inicio_fila - 1,  # Ajusta para iniciar desde la fila detectada\n",
    "                       header=0)  # La primera fila detectada se toma como encabezado\n",
    "\n",
    "    # Si la tabla inicia en una columna distinta a la primera, ajusta las columnas del DataFrame\n",
    "    if inicio_columna > 1:\n",
    "        df = df.iloc[:, inicio_columna - 1:]  # Elimina las columnas vacías anteriores al inicio\n",
    "    \n",
    "    # Retorna el DataFrame con los datos de la tabla\n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a5ee07-158e-4aaf-9a9e-2af21b4d256d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Función : Lectura automática de todos los archivos xlsx en una carpeta\n",
    "##\n",
    "#\n",
    "def Archivos_Carpeta(carpeta):\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .xlsx en una carpeta y organiza los datos en un diccionario de DataFrames.\n",
    "\n",
    "    Argumentos:\n",
    "    carpeta : str\n",
    "        Ruta de la carpeta que contiene los archivos de Excel.\n",
    "\n",
    "    Retorna:\n",
    "    tuple :\n",
    "        - dataframes : dict\n",
    "            Diccionario donde las claves son variables generadas (X1, X2, ...) y los valores son DataFrames.\n",
    "        - subcatalogo_df : pd.DataFrame\n",
    "            DataFrame que contiene el nombre de la variable y el archivo correspondiente.\n",
    "\n",
    "    Excepciones:\n",
    "    Imprime un mensaje de error si un archivo no puede procesarse.\n",
    "    \"\"\"\n",
    "    # Obtiene una lista de rutas completas de archivos .xlsx en la carpeta\n",
    "    archivos_excel = [os.path.join(carpeta, archivo) for archivo in os.listdir(carpeta) if archivo.endswith('.xlsx')]\n",
    "    \n",
    "    # Diccionario para almacenar los DataFrames\n",
    "    dataframes = {}\n",
    "    \n",
    "    # Lista para el subcatálogo con información de las variables y los archivos\n",
    "    subcatalogo = []\n",
    "\n",
    "    # Itera sobre los archivos encontrados en la carpeta\n",
    "    for idx, archivo in enumerate(archivos_excel):\n",
    "        try:\n",
    "            # Genera un nombre de variable (X1, X2, ...)\n",
    "            variable_name = f\"X{idx+1}\"\n",
    "            \n",
    "            # Carga la tabla de Excel usando la función Tabla_Excel\n",
    "            df = Tabla_Excel(archivo)\n",
    "            \n",
    "            # Agrega una columna al DataFrame con el nombre de la variable\n",
    "            df[\"Archivo\"] = variable_name \n",
    "            \n",
    "            # Almacena el DataFrame en el diccionario\n",
    "            dataframes[variable_name] = df\n",
    "            \n",
    "            # Agrega información del archivo al subcatálogo\n",
    "            subcatalogo.append({\"Variable\": variable_name, \"Archivo\": os.path.basename(archivo)})\n",
    "        except Exception as e:\n",
    "            # Imprime un mensaje si ocurre un error al procesar un archivo\n",
    "            print(f\"Error al procesar el archivo '{archivo}': {e}\")\n",
    "    \n",
    "    # Informa que todos los archivos se han leído correctamente\n",
    "    print(\"Todos los archivos se han leído correctamente.\")\n",
    "    \n",
    "    # Convierte la lista del subcatálogo a un DataFrame\n",
    "    subcatalogo_df = pd.DataFrame(subcatalogo)\n",
    "    \n",
    "    # Retorna el diccionario de DataFrames y el subcatálogo como un DataFrame\n",
    "    return (dataframes, subcatalogo_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "711f23f2-0583-466f-ab8a-d1ffaec6eadb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Función : Renombrar  columnas del DataFrames y generación de catálogo de equivalencias\n",
    "##\n",
    "#\n",
    "def Renombrar_Catalogo(dataframes):\n",
    "    \"\"\"\n",
    "    Renombra las columnas de un conjunto de DataFrames de forma uniforme y genera un catálogo de equivalencias.\n",
    "\n",
    "    La función toma las columnas del primer DataFrame como referencia y las renombra en todos los\n",
    "    DataFrames del diccionario, generando nombres estandarizados como C1, C2, ..., Cn.\n",
    "\n",
    "    Argumentos:\n",
    "    dataframes : dict\n",
    "        Diccionario de DataFrames donde las claves son nombres de variables (e.g., X1, X2) y los valores son DataFrames.\n",
    "\n",
    "    Retorna:\n",
    "    tuple :\n",
    "        - dataframes : dict\n",
    "            Diccionario de DataFrames con las columnas renombradas.\n",
    "        - catalogo_df : pd.DataFrame\n",
    "            DataFrame que muestra la equivalencia entre los nombres originales y los nombres uniformes.\n",
    "    \"\"\"\n",
    "    # Obtiene el nombre de la primera variable y sus columnas originales\n",
    "    nombre_variable_principal = next(iter(dataframes.keys()))  # Nombre de la primera variable (e.g., 'X1')\n",
    "    columnas_originales = dataframes[nombre_variable_principal].columns.tolist()\n",
    "    \n",
    "    # Genera nombres uniformes (C1, C2, ..., Cn) para las columnas\n",
    "    catalogo = {\"Original\": columnas_originales, \"Uniforme\": [f\"C{i+1}\" for i in range(len(columnas_originales))]}\n",
    "    catalogo_df = pd.DataFrame(catalogo)  # Crea el catálogo como DataFrame\n",
    "    \n",
    "    # Renombra las columnas de todos los DataFrames usando los nombres uniformes\n",
    "    for nombre_variable, df in dataframes.items():\n",
    "        nuevo_nombre_columnas = catalogo[\"Uniforme\"]\n",
    "        df.columns = nuevo_nombre_columnas\n",
    "    \n",
    "    # Informa que todas las columnas se han renombrado correctamente\n",
    "    print(\"Todos los archivos se han renombrado correctamente.\")\n",
    "    \n",
    "    # Retorna los DataFrames actualizados y el catálogo de nombres\n",
    "    return (dataframes, catalogo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44856708-9b74-4b6a-8b54-0fe33834d252",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "### Función : Validación y concatenación\n",
    "##\n",
    "#\n",
    "def Valida_Concatena(dataframes):\n",
    "    \"\"\"\n",
    "    Valida que todos los DataFrames tengan las mismas columnas y los concatena en un solo DataFrame.\n",
    "\n",
    "    Argumentos:\n",
    "    dataframes : dict\n",
    "        Diccionario de DataFrames donde las claves son nombres de variables y los valores son DataFrames.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame o None\n",
    "        - Un DataFrame concatenado si todos los DataFrames tienen las mismas columnas.\n",
    "        - None si hay inconsistencias en las columnas.\n",
    "    \"\"\"\n",
    "    # Obtiene la lista de columnas de referencia del primer DataFrame\n",
    "    columnas_referencia = list(next(iter(dataframes.values())).columns)\n",
    "    \n",
    "    # Valida que todos los DataFrames tengan las mismas columnas\n",
    "    for nombre_variable, df in dataframes.items():\n",
    "        if list(df.columns) != columnas_referencia:\n",
    "            print(f\"El DataFrame '{nombre_variable}' no tiene las mismas columnas que el resto.\")\n",
    "            print(f\"Columnas esperadas: {columnas_referencia}\")\n",
    "            print(f\"Columnas actuales: {list(df.columns)}\")\n",
    "            return None\n",
    "    \n",
    "    # Informa que la validación fue exitosa y procede a concatenar\n",
    "    print(\"Todos los DataFrames tienen las mismas columnas. Procediendo a concatenar...\")\n",
    "    datos_concatenados = pd.concat(dataframes.values(), ignore_index=True)\n",
    "    print(\"Concatenación exitosa.\")\n",
    "    \n",
    "    # Retorna el DataFrame concatenado\n",
    "    return (datos_concatenados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "388ac36b-85d2-4512-a043-8fb78d7ff2b3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Lectura_Hojas(carpeta):\n",
    "    \"\"\"\n",
    "    Lee todos los archivos .xlsx de una carpeta y todas sus hojas. \n",
    "    Renombra las columnas con un prefijo y crea catálogos para las hojas y las columnas.\n",
    "\n",
    "    :param carpeta: Ruta de la carpeta que contiene los archivos .xlsx.\n",
    "    :return: Diccionario con los DataFrames, catálogo de hojas y catálogo de columnas.\n",
    "    \"\"\"\n",
    "    # Obtener la lista de archivos .xlsx en la carpeta\n",
    "    archivos_excel = [os.path.join(carpeta, archivo) for archivo in os.listdir(carpeta) if archivo.endswith('.xlsx')]\n",
    "    dataframes = {}\n",
    "    catalogo_hojas = []\n",
    "    catalogo_columnas = []\n",
    "    \n",
    "    for archivo_idx, archivo in enumerate(archivos_excel):\n",
    "        try:\n",
    "            wb = load_workbook(archivo, data_only=True)  # Cargar el archivo Excel\n",
    "            for hoja_idx, hoja in enumerate(wb.sheetnames):\n",
    "                ws = wb[hoja]\n",
    "                inicio_fila = Tabla_Inicio(ws)  # Detectar inicio de la tabla\n",
    "                \n",
    "                # Leer la hoja específica con pandas desde la fila detectada\n",
    "                df = pd.read_excel(\n",
    "                    archivo,\n",
    "                    sheet_name=hoja,\n",
    "                    skiprows=inicio_fila,\n",
    "                    header=0\n",
    "                )\n",
    "                \n",
    "                # Renombrar columnas con el prefijo AGRS_\n",
    "                df, mapeo_columnas = Renombrar_CPre(df, prefijo=\"A_\")\n",
    "                \n",
    "                # Crear un nombre único para el DataFrame\n",
    "                variable_name = f\"Y{archivo_idx+1}_H{hoja_idx+1}\"  # Ej: X1_H1 para archivo 1, hoja 1\n",
    "                dataframes[variable_name] = df\n",
    "                \n",
    "                # Agregar al catálogo de hojas\n",
    "                catalogo_hojas.append({\n",
    "                    \"Variable\": variable_name,\n",
    "                    \"Archivo\": os.path.basename(archivo),\n",
    "                    \"Hoja\": hoja,\n",
    "                    \"Inicio_Fila\": inicio_fila\n",
    "                })\n",
    "                \n",
    "                # Agregar al catálogo de columnas\n",
    "                catalogo_columnas.append({\n",
    "                    \"Variable\": variable_name,\n",
    "                    \"Archivo\": os.path.basename(archivo),\n",
    "                    \"Hoja\": hoja,\n",
    "                    \"Mapeo_Columnas\": mapeo_columnas\n",
    "                })\n",
    "                \n",
    "                print(f\"Archivo '{os.path.basename(archivo)}', Hoja '{hoja}' cargado en la variable '{variable_name}'.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error al leer el archivo '{os.path.basename(archivo)}': {e}\")\n",
    "    \n",
    "    # Convertir los catálogos en DataFrames\n",
    "    catalogo_hojas_df = pd.DataFrame(catalogo_hojas)\n",
    "    catalogo_columnas_df = pd.DataFrame(catalogo_columnas)\n",
    "    \n",
    "    return (dataframes, catalogo_hojas_df, catalogo_columnas_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d060ef65-1dea-4960-9073-0ddde98ad554",
   "metadata": {},
   "source": [
    "### Funciones alternas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89d121b1-5eb7-4162-bf1a-49e0d53b0bb2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Objeto_Int(df, columnas):\n",
    "    \"\"\"\n",
    "    Convierte varias columnas de un DataFrame de tipo object a int64.\n",
    "\n",
    "    :param df: DataFrame que contiene las columnas a convertir.\n",
    "    :param columnas: Lista de nombres de columnas a convertir.\n",
    "    :return: DataFrame con las columnas convertidas a int64.\n",
    "    \"\"\"\n",
    "    for columna in columnas:\n",
    "        try:\n",
    "            # Reemplazar valores no numéricos con NaN, luego con 0, y convertir a int64\n",
    "            df[columna] = pd.to_numeric(df[columna], errors='coerce').fillna(0).astype('int64')\n",
    "            print(f\"Columna '{columna}' convertida exitosamente a int64.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error al convertir la columna '{columna}' a int64: {e}\")\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f25b10-b09d-4955-a814-2254fcfb653b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Column_Upp(df, columnas):\n",
    "    \"\"\"\n",
    "    Convierte el texto de varias columnas de un DataFrame a mayúsculas.\n",
    "\n",
    "    :param df: DataFrame que contiene las columnas a convertir.\n",
    "    :param columnas: Lista de nombres de columnas a convertir.\n",
    "    :return: DataFrame con las columnas convertidas a mayúsculas.\n",
    "    \"\"\"\n",
    "    for columna in columnas:\n",
    "        if columna in df.columns:  # Validar si la columna existe en el DataFrame\n",
    "            # Convertir los valores de la columna a mayúsculas\n",
    "            df[columna] = df[columna].astype(str).str.upper()\n",
    "            print(f\"Columna '{columna}' convertida exitosamente a mayúsculas.\")\n",
    "        else:\n",
    "            # Advertencia si la columna no existe en el DataFrame\n",
    "            print(f\"Advertencia: La columna '{columna}' no existe en el DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67862464-41c2-4170-891f-8d01a76a1c76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Restru_columna(df):\n",
    "    \"\"\"\n",
    "    Reestructura las columnas de un DataFrame tomando la primera fila como encabezado,\n",
    "    eliminando la primera fila y reiniciando los índices.\n",
    "\n",
    "    :param df: DataFrame a reestructurar.\n",
    "    :return: DataFrame reestructurado.\n",
    "    \"\"\"\n",
    "    # Asignar la primera fila como nombres de columnas\n",
    "    df.columns = df.iloc[0]\n",
    "    \n",
    "    # Eliminar la primera fila que ahora es redundante\n",
    "    df = df[1:]\n",
    "    \n",
    "    # Reiniciar los índices del DataFrame\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fea95604-7fa9-4adc-8a21-1ede0e748a06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Columnas_Unicas(df):\n",
    "    \"\"\"\n",
    "    Modifica las columnas duplicadas de un DataFrame para que sean únicas agregando un sufijo numérico.\n",
    "\n",
    "    :param df: DataFrame con columnas posiblemente duplicadas.\n",
    "    :return: DataFrame con nombres de columnas únicos.\n",
    "    \"\"\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():  # Detectar duplicados\n",
    "        dup_indices = cols[cols == dup].index\n",
    "        for i, idx in enumerate(dup_indices):\n",
    "            cols[idx] = f\"{dup}_{i+1}\"  # Agregar sufijo a los duplicados\n",
    "    df.columns = cols\n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a60936-7e57-4b55-9a08-dae7ba0f5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reno_Columnas(df):\n",
    "    \"\"\"\n",
    "    Renombra todas las columnas de un DataFrame con nombres secuenciales (T1, T2, ...).\n",
    "\n",
    "    :param df: DataFrame cuyas columnas serán renombradas.\n",
    "    :return: Tuple: DataFrame con columnas renombradas, diccionario con el mapeo original-nuevo.\n",
    "    \"\"\"\n",
    "    nuevos_nombres = {col: f\"T{i+1}\" for i, col in enumerate(df.columns)}\n",
    "    df = df.rename(columns=nuevos_nombres)\n",
    "    return (df, nuevos_nombres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d93eefc8-8fe3-4272-bb10-b316c6eda9db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Repla_V(df, columna, valor_a_reemplazar, nuevo_valor):\n",
    "    \"\"\"\n",
    "    Reemplaza valores específicos en una columna de un DataFrame.\n",
    "\n",
    "    :param df: DataFrame que contiene la columna.\n",
    "    :param columna: Nombre de la columna donde se reemplazarán los valores.\n",
    "    :param valor_a_reemplazar: Valor que será reemplazado.\n",
    "    :param nuevo_valor: Nuevo valor que se asignará en su lugar.\n",
    "    :return: DataFrame con los valores reemplazados.\n",
    "    \"\"\"\n",
    "    if columna in df.columns:  # Verificar que la columna existe\n",
    "        df[columna] = df[columna].replace(valor_a_reemplazar, nuevo_valor)\n",
    "        print(f\"Valores '{valor_a_reemplazar}' reemplazados por '{nuevo_valor}' en la columna '{columna}'.\")\n",
    "    else:\n",
    "        print(f\"Error: La columna '{columna}' no existe en el DataFrame.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e6ae17-a1e8-4d80-8c52-93fb264fbf4d",
   "metadata": {},
   "source": [
    "### Funciones Reglas de Negocio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94b641f3-db57-4e75-baea-24f25efcbb84",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Norma_Text(texto):\n",
    "    \"\"\"\n",
    "    Normaliza un texto convirtiéndolo a mayúsculas, eliminando espacios adicionales.\n",
    "\n",
    "    :param texto: Texto a normalizar.\n",
    "    :return: Texto normalizado.\n",
    "    \"\"\"\n",
    "    if isinstance(texto, str):\n",
    "        # Convertir a mayúsculas y eliminar espacios extra\n",
    "        return \" \".join(texto.strip().upper().split())\n",
    "    return (texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82e5fe33-8930-4455-995b-097ee752693e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Regla_Negocio(conca_dat, referencia, columna_conca, columna_referencia, columna_valor, nueva_columna):\n",
    "    \"\"\"\n",
    "    Agrega una nueva columna a un DataFrame basada en una regla de mapeo con otro DataFrame.\n",
    "\n",
    "    :param conca_dat: DataFrame principal donde se agregará la nueva columna.\n",
    "    :param referencia: DataFrame de referencia para el mapeo.\n",
    "    :param columna_conca: Columna en el DataFrame principal a comparar.\n",
    "    :param columna_referencia: Columna en el DataFrame de referencia para la clave de mapeo.\n",
    "    :param columna_valor: Columna en el DataFrame de referencia que contiene los valores a asignar.\n",
    "    :param nueva_columna: Nombre de la nueva columna a agregar en el DataFrame principal.\n",
    "    :return: DataFrame principal con la nueva columna agregada.\n",
    "    \"\"\"\n",
    "    # Normalizar las columnas involucradas\n",
    "    referencia[columna_referencia] = referencia[columna_referencia].apply(Norma_Text)\n",
    "    referencia[columna_valor] = referencia[columna_valor].apply(Norma_Text)\n",
    "    conca_dat[columna_conca] = conca_dat[columna_conca].apply(Norma_Text)\n",
    "    \n",
    "    # Crear un diccionario de mapeo\n",
    "    mapa_referencia = referencia.set_index(columna_referencia)[columna_valor].to_dict()\n",
    "    \n",
    "    # Aplicar la regla para agregar la nueva columna\n",
    "    conca_dat[nueva_columna] = conca_dat[columna_conca].apply(\n",
    "        lambda x: mapa_referencia[x] if x in mapa_referencia else \"In Activo\"\n",
    "    )\n",
    "    return (conca_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3defbf52-1d7f-4a99-a3e8-fb98f0bc57fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regla_Negocio2(conca_dat, referencia, columna_origen, columna_referencia, nueva_columna):\n",
    "    \"\"\"\n",
    "    Agrega una nueva columna a un DataFrame basada en la existencia de valores en otro DataFrame.\n",
    "\n",
    "    :param conca_dat: DataFrame principal donde se agregará la nueva columna.\n",
    "    :param referencia: DataFrame de referencia para verificar los valores.\n",
    "    :param columna_origen: Columna en el DataFrame principal cuyos valores serán verificados.\n",
    "    :param columna_referencia: Columna en el DataFrame de referencia que contiene los valores a verificar.\n",
    "    :param nueva_columna: Nombre de la nueva columna a agregar en el DataFrame principal.\n",
    "    :return: DataFrame principal con la nueva columna agregada.\n",
    "    \"\"\"\n",
    "    # Crear un conjunto de valores únicos de la columna de referencia\n",
    "    valores_referencia = set(referencia[columna_referencia])\n",
    "\n",
    "    # Usar np.where para asignar valores según la regla\n",
    "    conca_dat[nueva_columna] = np.where(\n",
    "        conca_dat[columna_origen].isin(valores_referencia),  # Si el valor está en el conjunto\n",
    "        conca_dat[columna_origen],                          # Mantener el valor original\n",
    "        \"In Activo\"                                         # De lo contrario, asignar \"in activo\"\n",
    "    )\n",
    "    return (conca_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43af7f3a-6cef-4f9f-8262-500cdeff1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos se han leído correctamente.\n"
     ]
    }
   ],
   "source": [
    "### > Lectura de multiples archivos xlsx de la carpeta\n",
    "#>\n",
    "carpeta_entrada = Entradas\n",
    "Usuarios, Usuarios_Catalogo = Archivos_Carpeta(carpeta_entrada)\n",
    "globals().update(Usuarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98fe33b7-fec6-49da-a8d0-9f7caa5fe6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los archivos se han renombrado correctamente.\n"
     ]
    }
   ],
   "source": [
    "### > Renombramiento de columnas y creación de catálogos\n",
    "#>\n",
    "Usuarios, Usuarios_columnas = Renombrar_Catalogo(Usuarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80a84dc4-d8bc-4d03-ab32-bcf7475f98cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todos los DataFrames tienen las mismas columnas. Procediendo a concatenar...\n",
      "Concatenación exitosa.\n"
     ]
    }
   ],
   "source": [
    "### > Concatenación de los multiples archivos en uno\n",
    "#>\n",
    "Usuarios_Concatenados = Valida_Concatena(Usuarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc2ea008-8181-46a5-a4a6-c44582cb3ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'C7' convertida exitosamente a int64.\n"
     ]
    }
   ],
   "source": [
    "### > Transformar de obj a int\n",
    "#>\n",
    "Column_Int = [\"C7\"]\n",
    "Usuarios_Concatenados = Objeto_Int(Usuarios_Concatenados, Column_Int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a534a244-1320-4719-b6c9-6d08283b2870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'C1' convertida exitosamente a mayúsculas.\n",
      "Columna 'C2' convertida exitosamente a mayúsculas.\n",
      "Columna 'C3' convertida exitosamente a mayúsculas.\n",
      "Columna 'C4' convertida exitosamente a mayúsculas.\n"
     ]
    }
   ],
   "source": [
    "### > Transformar a mayusculas\n",
    "#>\n",
    "Columnas_My = [\"C1\", \"C2\", \"C3\", \"C4\"]\n",
    "Usuarios_Concatenados = Column_Upp(Usuarios_Concatenados, Columnas_My)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc73269-b7d8-4647-80b1-c34e4f20227e",
   "metadata": {},
   "source": [
    "## Procesado de información\n",
    "### **Reglas de negocio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97e08a8f-eadd-4753-a7a0-2eebef899e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conca_Usuarios = Usuarios_Concatenados.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "639e4e3e-76db-4695-8f53-fc5843c153b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conca_Usuarios = Regla_Negocio(Conca_Usuarios, \n",
    "                               Y1_H1, \n",
    "                               columna_conca = \"C5\", \n",
    "                               columna_referencia = \"A_3\", \n",
    "                               columna_valor = \"A_1\", \n",
    "                               nueva_columna = \"EURFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6206219f-78c4-4736-8061-3982296aea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conca_Usuarios = Regla_Negocio(Conca_Usuarios, \n",
    "                               Y1_H1, \n",
    "                               columna_conca = \"C6\", \n",
    "                               columna_referencia = \"A_4\", \n",
    "                               columna_valor = \"A_5\", \n",
    "                               nueva_columna = \"VEUIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d83d4b91-4230-4b4a-93d4-c9c3793af254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores 'In Activo' reemplazados por 'Sin Cambio' en la columna 'AAUN'.\n"
     ]
    }
   ],
   "source": [
    "Conca_Usuarios = Regla_Negocio(Conca_Usuarios, \n",
    "                               Y2_H2_R, \n",
    "                               columna_conca = \"PNUSR\", \n",
    "                               columna_referencia = \"T1\", \n",
    "                               columna_valor = \"T8\", \n",
    "                               nueva_columna = \"AAUN\")\n",
    "Conca_Usuarios = Repla_V(Conca_Usuarios, \"AAUN\", \"In Activo\", \"Sin Cambio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f16b033-4019-4bc2-aec1-4e00d624664d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def Regla_Negocio3(conca_dat, referencia, columna_origen, columna_referencia, columna_valor, nueva_columna):\n",
    "    \"\"\"\n",
    "    Agrega una nueva columna a un DataFrame basada en la existencia de valores en otro DataFrame.\n",
    "\n",
    "    :param conca_dat: DataFrame principal donde se agregará la nueva columna.\n",
    "    :param referencia: DataFrame de referencia para verificar los valores.\n",
    "    :param columna_origen: Columna en el DataFrame principal cuyos valores serán verificados.\n",
    "    :param columna_referencia: Columna en el DataFrame de referencia que contiene los valores a verificar.\n",
    "    :param columna_valor: Columna en el DataFrame de referencia cuyos valores serán asignados si hay coincidencia.\n",
    "    :param nueva_columna: Nombre de la nueva columna a agregar en el DataFrame principal.\n",
    "    :return: DataFrame principal con la nueva columna agregada.\n",
    "    \"\"\"\n",
    "    # Crear un diccionario de referencia para buscar valores\n",
    "    valores_referencia = referencia.set_index(columna_referencia)[columna_valor].to_dict()\n",
    "\n",
    "    # Usar np.where para asignar valores según la regla\n",
    "    conca_dat[nueva_columna] = conca_dat[columna_origen].apply(\n",
    "        lambda x: valores_referencia.get(x, 'No se encontro')\n",
    "    )\n",
    "    \n",
    "    return conca_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfe300cc-86cf-4a35-ae33-447d8022cfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conca_Usuarios = Regla_Negocio3(conca_dat = Conca_Usuarios,\n",
    "                                referencia = AGS_R,\n",
    "                                columna_origen = 'C5',\n",
    "                                columna_referencia = 'RFC_CORTO',\n",
    "                                columna_valor = 'T8',\n",
    "                                nueva_columna = 'ADGA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "527576e6-d11f-41ec-9e40-c74f61b6e465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores 'No se encontro' reemplazados por 'Sin Información' en la columna 'EPRFC'.\n"
     ]
    }
   ],
   "source": [
    "Conca_Usuarios = Regla_Negocio3(conca_dat = Conca_Usuarios,\n",
    "                                referencia = AGS_R,\n",
    "                                columna_origen = 'C5',\n",
    "                                columna_referencia = 'RFC_CORTO',\n",
    "                                columna_valor = 'T8',\n",
    "                                nueva_columna = 'EPRFC')\n",
    "Conca_Usuarios = Repla_V(Conca_Usuarios, \"EPRFC\", \"No se encontro\", \"Sin Información\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bb949414-686d-41a2-903b-99bb2c9c8fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores 'No se encontro' reemplazados por 'Sin Información' en la columna 'EPNMB'.\n"
     ]
    }
   ],
   "source": [
    "Conca_Usuarios = Regla_Negocio3(conca_dat = Conca_Usuarios,\n",
    "                                referencia = AGS_R,\n",
    "                                columna_origen = 'C4',\n",
    "                                columna_referencia = 'NOMBRE',\n",
    "                                columna_valor = 'T8',\n",
    "                                nueva_columna = 'EPNMB')\n",
    "Conca_Usuarios = Repla_V(Conca_Usuarios, \"EPNMB\", \"No se encontro\", \"Sin Información\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
